{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swPQYMnPljRX"
   },
   "source": [
    "# Curso: SI7003 NLP\n",
    "## Homework 1 - Modelos de Lenguaje n-gram\n",
    "\n",
    "### Nombre Estudiante: <<...>>\n",
    "### email: @eafit.edu.co\n",
    "### fecha de entrega máxima: 23 de febrero\n",
    "### entregables: notebook hw1.ipynb y adicionales si los requiere, con los datasets empleados y los modelos generados.\n",
    "### todo eso debe ser un archivo por estudiante hw1.zip y entregado por Buzón en Interactiva Virtual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalar la librería KenLM\n",
    "\n",
    "## url: https://kheafield.com/code/kenlm/\n",
    "\n",
    "## 1. instanciar una máquina virtual Linux ubuntu 22.04\n",
    "\n",
    "## 2. descargar el fuente de kenlm y compilar:\n",
    "\n",
    "INSTALAR ESTAS DEPENDENCIAS:\n",
    "\n",
    "    sudo apt-get install build-essential libboost-all-dev cmake zlib1g-dev libbz2-dev liblzma-dev\n",
    "\n",
    "LUEGO INSTALAR KENLM\n",
    "\n",
    "    wget -O - https://kheafield.com/code/kenlm.tar.gz |tar xz\n",
    "    mkdir kenlm/build\n",
    "    cd kenlm/build\n",
    "    cmake ..\n",
    "    make -j2\n",
    "\n",
    "## 3. clonar el reposotorio github de la materia:\n",
    "\n",
    "    git clone https://github.com/mcdaeafit/si7003nlp.git\n",
    "\n",
    "## 4. probar la libreria:\n",
    "\n",
    "    cd $HOME\n",
    "    export PATH=$PATH:/$HOME/kenlm/build/bin\n",
    "    lmllz -o 5 < $HOME/si7003nlp/datasets/gutenberg-es/pg2000.txt > pg2000-modelo.arpa\n",
    "\n",
    "## LISTO !!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 1: Construcción de un modelo de lenguaje n-gram con KenLM\n",
    "## Objetivo: Entrenar un modelo de lenguaje usando tu propio corpus de texto\n",
    "## Tareas:\n",
    "### 1. Descarga un corpus de texto (por ejemplo, Wikipedia, libros en dominio público).\n",
    "### 2. Preprocesa el texto: normalización, tokenización, eliminación de caracteres especiales.\n",
    "### 3. Usa KenLM para entrenar un modelo de lenguaje con diferentes valores de n (ej. trigramas y pentagramas).\n",
    "### 4. Evalúa el modelo calculando la perplejidad sobre un conjunto de prueba (INVESTIGARLO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar un modelo de 3-gramas con interpolación\n",
    "lmplz -o 3 < corpus.txt > modelo.arpa\n",
    "\n",
    "# Convertir el modelo a formato binario para inferencia más rápida\n",
    "build_binary modelo.arpa modelo.bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escriba su propio comandos o código aca "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# escriba sus conclusiones del Reto 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 2: Evaluación de Modelos de Lenguaje (INVESTIGACIÓN)\n",
    "\n",
    "## Objetivo: Comparar la calidad de diferentes modelos de lenguaje.\n",
    "## Tareas:\n",
    "\n",
    "### 1. Entrena modelos con diferentes valores de n (ej. unigramas, bigramas, trigramas).\n",
    "### 2. Calcula la perplejidad sobre un conjunto de validación.\n",
    "### 3. Compara la perplejidad y analiza cómo cambia con el tamaño del n-grama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código ejemplo en shell\n",
    "query modelo.bin < test.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escriba su propio comandos o código aca "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# escriba sus conclusiones del Reto 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 3: Probabilidad de una Secuencia de Palabras\n",
    "\n",
    "## Objetivo: Calcular la probabilidad de una oración dada usando un modelo de lenguaje.\n",
    "## Tareas:\n",
    "\n",
    "### 1. Entrenar un modelo de 3-gramas.\n",
    "### 2. Usar KenLM para obtener la probabilidad de diferentes frases.\n",
    "### 3. Comparar las probabilidades entre frases gramaticalmente correctas y frases aleatorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codigo ejemplo en python:\n",
    "\n",
    "import kenlm\n",
    "\n",
    "model = kenlm.LanguageModel(\"modelo.bin\")\n",
    "\n",
    "sentence = \"Este es un ejemplo de oración\"\n",
    "print(f\"Log-probabilidad: {model.score(sentence)}\")\n",
    "print(f\"Perplejidad: {10 ** (-model.score(sentence) / len(sentence.split()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidad de Frases en Español con un corpus en español\n",
    "sentences = [\n",
    "    \"El clima está muy agradable hoy.\",\n",
    "    \"Hoy clima está muy agradable el.\",\n",
    "    \"El coche rojo es más rápido que el azul.\"\n",
    "]\n",
    "\n",
    "for s in sentences:\n",
    "    print(f\"'{s}': {model.score(s)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escriba su propio comandos o código aca "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# escriba sus conclusiones del Reto 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 4. Generación de Texto Basado en Probabilidades\n",
    "\n",
    "## Objetivo: Usar un modelo de lenguaje para generar texto de manera probabilística.\n",
    "## Tareas:\n",
    "\n",
    "### 1. Implementar una función que, dado un modelo entrenado, genere texto palabra por palabra.\n",
    "### 2. Comparar la coherencia del texto generado con diferentes valores de n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de generación en Python:\n",
    "import random\n",
    "\n",
    "def generate_text(model, seed_text, max_words=50):\n",
    "    words = seed_text.split()\n",
    "    for _ in range(max_words):\n",
    "        candidates = [(word, model.score(\" \".join(words + [word]))) for word in vocab]\n",
    "        next_word = max(candidates, key=lambda x: x[1])[0]\n",
    "        words.append(next_word)\n",
    "    return \" \".join(words)\n",
    "\n",
    "vocab = [\"este\", \"es\", \"un\", \"ejemplo\", \"de\", \"generación\", \"de\", \"texto\"]\n",
    "print(generate_text(model, \"este es\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escriba su propio comandos o código aca "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# escriba sus conclusiones del Reto 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 5: Detección de Texto Anómalo\n",
    "\n",
    "## Objetivo: Usar modelos n-gram para detectar frases fuera de distribución.\n",
    "## Tareas:\n",
    "\n",
    "### 1. Entrenar un modelo en un dominio específico (ej. noticias, literatura).\n",
    "### 2. Calcular la probabilidad de frases tomadas de otro dominio (ej. tweets, mensajes informales).\n",
    "### 3. Identificar oraciones con baja probabilidad como anomalías."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# código ejemplo en python:\n",
    "\n",
    "text1 = \"El presidente anunció nuevas políticas económicas\"\n",
    "text2 = \"lol wtf esto es épico bro jajaja\"\n",
    "\n",
    "print(f\"Perplejidad texto 1: {10 ** (-model.score(text1) / len(text1.split()))}\")\n",
    "print(f\"Perplejidad texto 2: {10 ** (-model.score(text2) / len(text2.split()))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escriba su propio comandos o código aca "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# escriba sus conclusiones del Reto 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de Textos por Dominio con KenLM\n",
    "\n",
    "## Objetivo: Entrenar modelos de lenguaje específicos para diferentes dominios y utilizarlos para clasificar textos desconocidos según su estilo.\n",
    "\n",
    "### Tareas:\n",
    "\n",
    "### 1. Recolectar corpus en español de distintos dominios:\n",
    "#### * Noticias (Ejemplo: artículos de El País, La Nación, BBC Mundo).\n",
    "#### * Literatura (Ejemplo: libros en dominio público como Don Quijote o La Celestina).\n",
    "#### * Redes sociales / Conversaciones informales (Ejemplo: tweets, mensajes de WhatsApp, subtítulos de OpenSubtitles).\n",
    "### 2. Entrenar un modelo KenLM para cada dominio (ej. modelo_noticias.bin, modelo_literatura.bin, etc.).\n",
    "### 3. Clasificar nuevos textos midiendo su perplejidad con cada modelo y asignándolo al modelo que le dé menor perplejidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 6: Entrenar Modelos de Lenguaje por Dominio\n",
    "Descargar y preprocesar corpus: (buscar esos corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wget -O noticias.txt \"URL_CORPUS_NOTICIAS\"\n",
    "wget -O literatura.txt \"URL_CORPUS_LITERATURA\"\n",
    "wget -O redes.txt \"URL_CORPUS_REDES\"\n",
    "\n",
    "# Entrenar modelos para cada dominio\n",
    "lmplz -o 3 < noticias.txt > modelo_noticias.arpa\n",
    "lmplz -o 3 < literatura.txt > modelo_literatura.arpa\n",
    "lmplz -o 3 < redes.txt > modelo_redes.arpa\n",
    "\n",
    "# Convertir a binario para inferencia más rápida\n",
    "build_binary modelo_noticias.arpa modelo_noticias.bin\n",
    "build_binary modelo_literatura.arpa modelo_literatura.bin\n",
    "build_binary modelo_redes.arpa modelo_redes.bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escriba su propio comandos o código aca "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# escriba sus conclusiones del Reto 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 7: Clasificación de un Texto Nuevo\n",
    "### Lógica: El modelo que asigne menor perplejidad es el que más se ajusta al dominio del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kenlm\n",
    "\n",
    "# Cargar modelos\n",
    "models = {\n",
    "    \"Noticias\": kenlm.LanguageModel(\"modelo_noticias.bin\"),\n",
    "    \"Literatura\": kenlm.LanguageModel(\"modelo_literatura.bin\"),\n",
    "    \"Redes Sociales\": kenlm.LanguageModel(\"modelo_redes.bin\"),\n",
    "}\n",
    "\n",
    "def classify_text(text):\n",
    "    perps = {name: 10 ** (-model.score(text) / len(text.split())) for name, model in models.items()}\n",
    "    best_fit = min(perps, key=perps.get)\n",
    "    return best_fit, perps\n",
    "\n",
    "# Texto de prueba\n",
    "text = \"El gobierno anunció nuevas reformas económicas para el país.\"\n",
    "\n",
    "category, perplejidades = classify_text(text)\n",
    "print(f\"Clasificación: {category}\")\n",
    "print(f\"Perplejidades: {perplejidades}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escriba su propio comandos o código aca "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# escriba sus conclusiones del Reto 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 8:Evaluación y Mejoras\n",
    "\n",
    "### 1. Evaluar precisión: Probar con textos etiquetados y medir qué porcentaje de clasificaciones son correctas.\n",
    "### 2. Optimizar: Aumentar el tamaño del corpus o usar bigramas vs trigramas para mejorar la clasificación.\n",
    "### Casos reales: Se puede usar para detectar si un mensaje es formal (noticia) o informal (red social)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escriba su propio comandos o código aca "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# escriba sus conclusiones del Reto 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 9 y 10: Investigador alguna aplicación especifica con su respectivo ejemplo con KenLM para hacer una de las siguientes tareas:\n",
    "\n",
    "## 1. Análisis de textos (ej: históricos, jurídicos, financieros, etc)\n",
    "## 2. Modelos de lenguaje para chatbots o asistentes virtuales.\n",
    "## 3. Filtrado de contenido ofensivo o spam.\n",
    "## 4. Corrección ortográfica basada en modelos n-gram.\n",
    "## 5. Optimización de autocompletado en buscadores o escritura de texto en editores, email, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escriba su propio comandos o código aca "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# escriba sus conclusiones del Reto 9 y 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retos del 11 al 15\n",
    "# Modelos de lenguaje n-gram con librerias de redes neuronales como PyTorch\n",
    "# Pasos:\n",
    "\n",
    "## 1. Utilizar los mismos conjuntos de ratos empleados para los retos 1 al 5 o 6 al 10\n",
    "## 2. Preparación de datos del Corpus (reto 11)\n",
    "## 3. creación del modelo n-gram con Pytorch (reto 12)\n",
    "## 4. Comparar Perplejidad en Nuevas Frases con PyTorch y KenLM (reto 13)\n",
    "## 5. genere las principales conclusiones de esta comparación respecto a: (reto 14 y 15)\n",
    "### 5.1 Perplejidad para alguna tarea\n",
    "### 5.2 Velocidad de procesamiento\n",
    "### 5.3 complejidad de los textos\n",
    "### 5.4 desempeño en tareas como corrección ortográfica o predicción de palabras\n",
    "\n",
    "## Puede ayudarse de libros de PyTorch \n",
    "## algunos códigos ejemplo de ayuda a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación de texto\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Cargar corpus\n",
    "with open(\"corpus_espanol.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read().lower()\n",
    "\n",
    "# Preprocesamiento básico\n",
    "text = re.sub(r\"[^a-záéíóúñ ]\", \"\", text)  # Eliminar caracteres especiales\n",
    "tokens = text.split()\n",
    "vocab = list(set(tokens))\n",
    "word2idx = {word: i for i, word in enumerate(vocab)}\n",
    "idx2word = {i: word for word, i in word2idx.items()}\n",
    "\n",
    "print(f\"Vocabulario: {len(vocab)} palabras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# entrenar el modelo n-gram con Pytorch\n",
    "class NGramDataset(Dataset):\n",
    "    def __init__(self, tokens, n=3):\n",
    "        self.data = []\n",
    "        for i in range(len(tokens) - n):\n",
    "            context = tokens[i:i+n-1]\n",
    "            target = tokens[i+n-1]\n",
    "            self.data.append((context, target))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context, target = self.data[idx]\n",
    "        context_idx = torch.tensor([word2idx[w] for w in context], dtype=torch.long)\n",
    "        target_idx = torch.tensor(word2idx[target], dtype=torch.long)\n",
    "        return context_idx, target_idx\n",
    "\n",
    "# Hiperparámetros\n",
    "N_GRAM = 3\n",
    "EMBED_DIM = 64\n",
    "HIDDEN_DIM = 128\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "dataset = NGramDataset(tokens, N_GRAM)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Definir modelo\n",
    "class NGramModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
    "        super(NGramModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim * (N_GRAM - 1), hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).view(x.shape[0], -1)\n",
    "        x = self.relu(self.fc(x))\n",
    "        return self.output(x)\n",
    "\n",
    "model = NGramModel(len(vocab), EMBED_DIM, HIDDEN_DIM)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entrenamiento\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for context, target in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(context)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Época {epoch+1}, Pérdida: {total_loss / len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de perplejidad en PyTorch\n",
    "\n",
    "import math\n",
    "\n",
    "def calculate_perplexity_pytorch(model, sentence):\n",
    "    words = sentence.split()\n",
    "    n_grams = [words[i:i+N_GRAM-1] for i in range(len(words) - N_GRAM + 1)]\n",
    "    total_log_prob = 0\n",
    "    for context in n_grams:\n",
    "        context_idx = torch.tensor([word2idx[w] for w in context], dtype=torch.long).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            output = model(context_idx).squeeze(0)\n",
    "            probs = torch.softmax(output, dim=0)\n",
    "            next_word = words[len(context)]\n",
    "            prob = probs[word2idx[next_word]].item()\n",
    "            total_log_prob += math.log(prob) if prob > 0 else 0\n",
    "    perplexity = math.exp(-total_log_prob / len(n_grams))\n",
    "    return perplexity\n",
    "\n",
    "test_sentence = \"el presidente anunció nuevas reformas económicas\"\n",
    "print(f\"Perplejidad PyTorch: {calculate_perplexity_pytorch(model, test_sentence)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inserte acá y en más celdas si lo requiere su propio código con explicaciones o comentarios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# documente sus propias conclusiones de los retos 11 al 15"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "lda-gensim-example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cs224n",
   "language": "python",
   "name": "cs224n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
